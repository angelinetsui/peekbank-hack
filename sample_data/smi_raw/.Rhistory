library(eyetrackingR)
library(tidyverse)
library(cowplot) #include this package for some nice default aesthetics
bySub <- ddply(d, .(Sub.Num,TrialType,Time), summarize,
N = sum(!is.na(Accuracy)),
Accuracy = mean(Accuracy,na.rm=TRUE))
bySub <- ddply(d, .(Sub.Num,TrialType,Time), summarize,
N = sum(!is.na(Accuracy)),
Accuracy = mean(Accuracy,na.rm=TRUE))
## load libraries
library(eyetrackingR)
library(tidyverse)
library(cowplot) #include this package for some nice default aesthetics
## load data
mydata<- read.csv("./data/switching_data.csv")
## load data
mydata<- read.csv("./data/switching_data.csv")
## Creates initial dataframe
data <- make_eyetrackingr_data(mydata,
participant_column = "id",
trial_column = "trial.number.unique",
time_column = "TrialTimestamp",
trackloss_column = "trackloss",
aoi_columns = c('look.target', 'look.distractor'),
treat_non_aoi_looks_as_missing = TRUE)
## Creates dataframe that is only data within window of analysis, 360ms after noun onset (which occurs at 5400ms)
response_window <- subset_by_window(data,
window_start_time = 5760, #360ms after noun onset
window_end_time = 7400, #2000ms after noun onset
rezero = FALSE)
## Gets rid of rows with trackloss within window of analysis
response_window_clean <- clean_by_trackloss(data = response_window,
trial_prop_thresh = (1 - 750/(2000-360))) # Need at least 750ms looking = 750/(2000-360)
## Aggregate by subject across response window
response_window_agg_by_sub <- make_time_window_data(response_window_clean,
aois = "look.target",
predictor_columns=c("trial.type", "age.group", "switch.type", "per.dom", "per.nondom", "lang.mix"),
summarize_by = "id",
other_dv_columns = c("PupilLeft", "PupilRight"))
#add parameter Exp to track experiment names from paper
response_window_agg_by_sub <- unite(response_window_agg_by_sub, exp, switch.type,age.group, remove=FALSE)
response_window_agg_by_sub <- response_window_agg_by_sub %>%
mutate(exp=recode_factor(exp,
"Within-sentence_20-month-olds" = "Exp 1: Infants",
"Within-sentence_Adults" = "Exp 2: Adults",
"Across-sentence_20-month-olds" = "Exp 3: Infants",
"Across-sentence_Adults" = "Exp 3: Adults"))
## Means and SDs by trial type, stored in the data frame mean_df
mean_df <- response_window_agg_by_sub %>% # Get all the means
group_by(switch.type, age.group, trial.type,exp) %>%
summarise(target.mean = mean(Prop), target.sd = sd(Prop), n = length(unique(id)))
#plot
ggplot(mean_df,aes(trial.type,target.mean,fill=trial.type,color=trial.type))+
geom_bar(stat="identity",color="black",size=1.2,alpha=0.3)+
scale_fill_brewer(direction=-1,palette="Set1")+
scale_color_brewer(direction=-1,palette="Set1")+
geom_jitter(data=response_window_agg_by_sub,aes(y=Prop),width=0.1,shape=21,fill=NA,size=2)+
geom_errorbar(aes(ymin=target.mean-target.sd/sqrt(n),ymax=target.mean+target.sd/sqrt(n)),width=0.2,color="black")+
geom_hline(yintercept=0.5,linetype="solid")+
xlab("Trial type")+
ylab("Proportion target looking")+
theme(legend.position="none",text = element_text(size=24),axis.text.x = element_text(size=20),axis.text.y = element_text(size=20))+
scale_y_continuous(breaks=c(0,0.2,0.4,0.6,0.8,1.0))+
facet_grid(~exp)
#bin the data into 200ms time bins (apparent approach in PNAS figure 3)
response_window$TimeBin200 <- round(response_window$TrialTimestamp/200,0)
response_window$TimeBin200Ms <- response_window$TimeBin200*200
response_window$TimeBin200Ms_Noun <- response_window$TimeBin200Ms - 5400
## Gets rid of rows with trackloss within window of analysis (same as above)
response_window_clean <- clean_by_trackloss(data = response_window,
trial_prop_thresh = (1 - 750/(2000-360))) # Need at least 750ms looking = 750/(2000-360)
#summarize data first within each subject
response_window_timecourse_by_sub_200ms <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,TimeBin200Ms,TimeBin200Ms_Noun) %>%
summarize(acc = mean(look.target,na.rm=T))
#summarize data across subjects
response_window_timecourse_across_sub_200ms <- response_window_timecourse_by_sub_200ms %>%
group_by(switch.type,age.group,trial.type,Carrier,TimeBin200Ms,TimeBin200Ms_Noun) %>%
summarize(mean.target = mean(acc,na.rm=T),se.target = sd(acc)/sqrt(length(acc)))
#add parameter Exp to track experiment names from paper
response_window_timecourse_across_sub_200ms <- unite(response_window_timecourse_across_sub_200ms, exp, switch.type,age.group, remove=FALSE)
response_window_timecourse_across_sub_200ms$exp=as.factor(response_window_timecourse_across_sub_200ms$exp)
response_window_timecourse_across_sub_200ms <- response_window_timecourse_across_sub_200ms %>%
mutate(exp=recode_factor(exp,
"Within-sentence_20-month-olds" = "Exp 1: Infants",
"Within-sentence_Adults" = "Exp 2: Adults",
"Across-sentence_20-month-olds" = "Exp 3: Infants",
"Across-sentence_Adults" = "Exp 3: Adults"),ordered=T)
ggplot(filter(response_window_timecourse_across_sub_200ms,!is.na(Carrier)),aes(TimeBin200Ms_Noun,mean.target,color=trial.type))+
geom_smooth(se=F,size=2)+
geom_point(aes(shape=trial.type),size=4,alpha=0.5)+
geom_errorbar(aes(ymin=mean.target-se.target,ymax=mean.target+se.target),width=0)+
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
xlim(0,2000)+
xlab("Time from target word onset (ms)")+
scale_color_brewer(direction=-1,palette="Set1")+
theme(legend.position=c(0.05,0.9))+
facet_grid(Carrier~exp)
## Gets rid of rows with trackloss within window of analysis (same as above)
response_window_clean <- clean_by_trackloss(data = response_window,
trial_prop_thresh = (1 - 750/(2000-360))) # Need at least 750ms looking = 750/(2000-360)
sample_rate=1000/60
response_window_clean$TimeBin16 <- round(response_window_clean$TrialTimestamp/sample_rate,0)*sample_rate
#summarize data first within each subject
response_window_timecourse_by_sub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,TimeBin16) %>%
summarize(acc = mean(look.target,na.rm=T), TrialTimestamp=TrialTimestamp[1])
#bin the data into 200ms time bins (apparent approach in PNAS figure 3)
response_window_timecourse_by_sub$TimeBin200 <- round(response_window_timecourse_by_sub$TrialTimestamp/200,0)
response_window_timecourse_by_sub$TimeBin200Ms <- response_window_timecourse_by_sub$TimeBin200*200
response_window_timecourse_by_sub$TimeBin200Ms_Noun <- response_window_timecourse_by_sub$TimeBin200Ms - 5400
response_window_timecourse_by_sub_200ms <- response_window_timecourse_by_sub %>%
group_by(switch.type,age.group,id,trial.type,Carrier,TimeBin200Ms_Noun) %>%
summarize(acc = mean(acc,na.rm=T))
#summarize data across subjects
response_window_timecourse_across_sub_200ms <- response_window_timecourse_by_sub_200ms %>%
group_by(switch.type,age.group,trial.type,Carrier,TimeBin200Ms_Noun) %>%
summarize(mean.target = mean(acc,na.rm=T),se.target = sd(acc)/sqrt(length(acc)))
#add parameter Exp to track experiment names from paper
response_window_timecourse_across_sub_200ms <- unite(response_window_timecourse_across_sub_200ms, exp, switch.type,age.group, remove=FALSE)
response_window_timecourse_across_sub_200ms$exp=as.factor(response_window_timecourse_across_sub_200ms$exp)
response_window_timecourse_across_sub_200ms <- response_window_timecourse_across_sub_200ms %>%
mutate(exp=recode_factor(exp,
"Within-sentence_20-month-olds" = "Exp 1: Infants",
"Within-sentence_Adults" = "Exp 2: Adults",
"Across-sentence_20-month-olds" = "Exp 3: Infants",
"Across-sentence_Adults" = "Exp 3: Adults"),ordered=T)
## Gets rid of rows with trackloss within window of analysis (same as above)
response_window_clean <- clean_by_trackloss(data = response_window,
trial_prop_thresh = (1 - 750/(2000-360))) # Need at least 750ms looking = 750/(2000-360)
sample_rate=1000/60
response_window_clean$TimeBin16 <- round(response_window_clean$TrialTimestamp/sample_rate,0)*sample_rate
#summarize data first within each subject
response_window_timecourse_by_sub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,TimeBin16) %>%
summarize(acc = mean(look.target,na.rm=T), TrialTimestamp=TrialTimestamp[1])
#bin the data into 200ms time bins (apparent approach in PNAS figure 3)
response_window_timecourse_by_sub$TimeBin200 <- round(response_window_timecourse_by_sub$TrialTimestamp/200,0)
response_window_timecourse_by_sub$TimeBin200Ms <- response_window_timecourse_by_sub$TimeBin200*200
response_window_timecourse_by_sub$TimeBin200Ms_Noun <- response_window_timecourse_by_sub$TimeBin200Ms - 5400
response_window_timecourse_by_sub_200ms <- response_window_timecourse_by_sub %>%
group_by(switch.type,age.group,id,trial.type,Carrier,TimeBin200Ms_Noun) %>%
summarize(acc = mean(acc,na.rm=T))
#summarize data across subjects
response_window_timecourse_across_sub_200ms <- response_window_timecourse_by_sub_200ms %>%
group_by(switch.type,age.group,trial.type,Carrier,TimeBin200Ms_Noun) %>%
summarize(mean.target = mean(acc,na.rm=T),se.target = sd(acc)/sqrt(length(acc)))
#add parameter Exp to track experiment names from paper
response_window_timecourse_across_sub_200ms <- unite(response_window_timecourse_across_sub_200ms, exp, switch.type,age.group, remove=FALSE)
response_window_timecourse_across_sub_200ms$exp=as.factor(response_window_timecourse_across_sub_200ms$exp)
response_window_timecourse_across_sub_200ms <- response_window_timecourse_across_sub_200ms %>%
mutate(exp=recode_factor(exp,
"Within-sentence_20-month-olds" = "Exp 1: Infants",
"Within-sentence_Adults" = "Exp 2: Adults",
"Across-sentence_20-month-olds" = "Exp 3: Infants",
"Across-sentence_Adults" = "Exp 3: Adults"),ordered=T)
ggplot(filter(response_window_timecourse_across_sub_200ms,!is.na(Carrier)),aes(TimeBin200Ms_Noun,mean.target,color=trial.type))+
geom_smooth(se=F,size=2)+
geom_point(aes(shape=trial.type),size=4,alpha=0.5)+
geom_errorbar(aes(ymin=mean.target-se.target,ymax=mean.target+se.target),width=0)+
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
xlim(0,2000)+
xlab("Time from target word onset (ms)")+
scale_color_brewer(direction=-1,palette="Set1")+
theme(legend.position=c(0.05,0.9))+
facet_grid(Carrier~exp)
ggplot(filter(response_window_timecourse_across_sub_200ms,!is.na(Carrier)),aes(TimeBin200Ms_Noun,mean.target,color=trial.type))+
geom_smooth(se=F,size=2)+
geom_point(aes(shape=trial.type),size=4,alpha=0.5)+
geom_errorbar(aes(ymin=mean.target-se.target,ymax=mean.target+se.target),width=0)+
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
xlim(0,2000)+
xlab("Time from target word onset (ms)")+
scale_color_brewer(direction=-1,palette="Set1")+
theme(legend.position=c(0.05,0.9))+
facet_grid(Carrier~exp)
View(data)
str(data)
bySub <- ddply(d, .(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimeStamp), summarize,
N = sum(!is.na(acc)),
Accuracy = mean(acc,na.rm=TRUE))
bySub <- d %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimeStamp) %>%
summarize(N = sum(!is.na(acc)),Accuracy = mean(acc,na.rm=TRUE))
bySub <- data %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimeStamp) %>%
summarize(N = sum(!is.na(acc)),Accuracy = mean(acc,na.rm=TRUE))
bySub <- data %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimestamp) %>%
summarize(N = sum(!is.na(acc)),Accuracy = mean(acc,na.rm=TRUE))
bySub <- data %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimestamp) %>%
summarize(N = sum(!is.na(acc)),Accuracy = mean(acc,na.rm=TRUE))
View(bySub)
bySub <- data %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimestamp) %>%
summarize(N = sum(!is.na(acc)),Accuracy = mean(look.target,na.rm=TRUE))
View(bySub)
bySub <- data %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimestamp) %>%
summarize(N = sum(!is.na(look.target)),Accuracy = mean(look.target,na.rm=TRUE))
View(bySub)
## Gets rid of rows with trackloss within window of analysis (same as above)
response_window_clean <- clean_by_trackloss(data = response_window,
trial_prop_thresh = (1 - 750/(2000-360))) # Need at least 750ms looking = 750/(2000-360)
sample_rate=1000/60
response_window_clean$TimeBin16 <- round(response_window_clean$TrialTimestamp/sample_rate,0)*sample_rate
View(response_window_clean)
bySub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TrialTimestamp) %>%
summarize(N = sum(!is.na(look.target)),Accuracy = mean(look.target,na.rm=TRUE))
View(bySub)
bySub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TimeBin16) %>%
summarize(N = sum(!is.na(look.target)),Accuracy = mean(look.target,na.rm=TRUE))
sample_rate=1000/60
response_window_clean$TimeBin16 <- round(response_window_clean$TrialTimestamp/sample_rate,0)*sample_rate
View(response_window_clean)
round(response_window_clean$TrialTimestamp/sample_rate,0)*sample_rate
round(response_window_clean$TrialTimestamp/sample_rate,0)
response_window_timecourse_by_sub$TimeBin16_Noun <- response_window_timecourse_by_sub$TimeBin16 - 5400
bySub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TimeBin16_Noun) %>%
summarize(N = sum(!is.na(look.target)),Accuracy = mean(look.target,na.rm=TRUE))
response_window_clean$TimeBin16_Noun <- response_window_clean$TimeBin16 - 5400
bySub <- response_window_clean %>%
group_by(switch.type,age.group,id,trial.type,Carrier,Carrier,TimeBin16_Noun) %>%
summarize(N = sum(!is.na(look.target)),Accuracy = mean(look.target,na.rm=TRUE))
hist(bySub$N)
byGroup <- ddply(bySub, .(TimeBin16_Noun,switch.type,age.group,trial.type,Carrier), summarize,
N = sum(!is.na(Accuracy)),
SD = sd(Accuracy,na.rm=TRUE),
SE = SD/sqrt(N),
Accuracy = mean(Accuracy,na.rm=TRUE))
byGroup <- bySub %>%
group_by(TimeBin16_Noun,switch.type,age.group,trial.type,Carrier) %>%
summarize(N = sum(!is.na(Accuracy)),
SD = sd(Accuracy,na.rm=TRUE),
SE = SD/sqrt(N),
Accuracy = mean(Accuracy,na.rm=TRUE))
View(byGroup)
# add the upper and lower SE bars
byGroup$lower <- byGroup$Accuracy - byGroup$SE
byGroup$upper <- byGroup$Accuracy + byGroup$SE
#add parameter Exp to track experiment names from paper
byGroup <- unite(byGroup, exp, switch.type,age.group, remove=FALSE)
byGroup$exp=as.factor(byGroup$exp)
byGroup <- byGroup %>%
mutate(exp=recode_factor(exp,
"Within-sentence_20-month-olds" = "Exp 1: Infants",
"Within-sentence_Adults" = "Exp 2: Adults",
"Across-sentence_20-month-olds" = "Exp 3: Infants",
"Across-sentence_Adults" = "Exp 3: Adults"),ordered=T)
View(byGroup)
ggplot(byGroup, aes(x=TimeBin16_Noun, y=Accuracy, fill=trial.type, color=trial.type)) +
geom_line() +
geom_smooth(aes(ymin=lower, ymax=upper), stat="identity") +
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
scale_color_brewer(direction=-1,palette="Set1")+
labs(x='Time since target onset (in ms)',y='Proportion Looking to Target') +
facet_grid(Carrier~exp)
ggplot(filter(byGroup, !is.na(Carrier)), aes(x=TimeBin16_Noun, y=Accuracy, fill=trial.type, color=trial.type)) +
geom_line() +
geom_smooth(aes(ymin=lower, ymax=upper), stat="identity") +
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
scale_color_brewer(direction=-1,palette="Set1")+
labs(x='Time since target onset (in ms)',y='Proportion Looking to Target') +
facet_grid(Carrier~exp)
ggplot(filter(byGroup, !is.na(Carrier)), aes(x=TimeBin16_Noun, y=Accuracy, fill=trial.type, color=trial.type)) +
geom_line() +
geom_smooth(aes(ymin=lower, ymax=upper), stat="identity") +
geom_vline(xintercept=360,linetype="dashed")+
geom_hline(yintercept=0.5,linetype="solid")+
scale_color_brewer(direction=-1,palette="Set1")+
scale_fill_brewer(direction=-1,palette="Set1")+
labs(x='Time since target onset (in ms)',y='Proportion Looking to Target') +
facet_grid(Carrier~exp)
(2+2+16*15)/(27*26)
(2+16*15)/(27*26)
log2(0.5)
log2(1)
log2(1/16)
log2(1/8)
log2(0)
library(gtools)
#### Load data ####
d1=read.csv("Active_V1_active_data.txt",sep="\t")
d2=read.csv("Active_V2_active_data.txt",sep="\t")
d3=read.csv("Active_V3_active_data.txt",sep="\t")
d4=read.csv("Active_V4_active_data.txt",sep="\t")
d6=read.csv("Active_V6_active_data.txt",sep="\t")
d7=read.csv("Active_V7_active_data.txt",sep="\t")
d1$Experiment=1
d2$Experiment=2
d3$Experiment=3
d4$Experiment=4
d6$Experiment=6
d7$Experiment=7
d = smartbind(d1,d2,d3,d4,d6,d7)
1400/3
55/1.1
45/1.1
10/1.1
5.20+34.65+28.48+4.76
549.39/2
467/2
700-233.50
html_tag_audio("../recording_stimuli/final/doopy.wav", type = "wav")
#packages
library(tidyverse)
#packages
library(tidyverse)
library(cowplot)
library(knitr)
library(htmltools)
library(glue)
theme_set(theme_cowplot())
###function for adding html audio
html_tag_audio <- function(file, type = c("wav")) {
type <- match.arg(type)
htmltools::tags$audio(
controls = NA,
htmltools::tags$source(
src = file,
type = glue::glue("audio/{type}", type = type)
)
)
}
html_tag_audio("../recording_stimuli/final/doopy.wav", type = "wav")
?htmltools::tags
htmltools::tags$source(
src = file,
type = glue::glue("audio/{type}", type = type)
)
type=c("wav")
file="../recording_stimuli/final/doopy.wav"
type="wav"
htmltools::tags$audio(
controls = T,
htmltools::tags$source(
src = file,
type = glue::glue("audio/{type}", type = type)
)
)
type <- match.arg(type)
htmltools::tags$audio(
controls = NA,
htmltools::tags$source(
src = file,
type = glue::glue("audio/{type}", type = type)
)
)
list_d <- data.frame(list_1=list1,list_2=list2,audio=c('<audio controls>
<source src="audio/doopy.wav" type="audio/wav"/>
</audio>'))
library(tidyverse)
library(cowplot)
library(knitr)
library(htmltools)
library(glue)
theme_set(theme_cowplot())
###function for adding html audio
html_tag_audio <- function(file, type = "wav") {
type <- match.arg(type)
htmltools::tags$audio(
controls = NA,
htmltools::tags$source(
src = file,
type = glue::glue("audio/{type}", type = type)
)
)
}
#read in data
d <- read.csv("WordProperties - phonotactic probability.csv")
#clean up the data frame
d <- d %>%
select(word,init_sound,final_sound,num_segments,num_biphones,adult_corpus_avg_segment_phonotactic_probability,adult_corpus_avg_biphone_phonotactic.probability) %>%
rename(seg_pp=adult_corpus_avg_segment_phonotactic_probability,bi_pp=adult_corpus_avg_biphone_phonotactic.probability)
# define pairs for each list and add info to data frame
list1=c("toma","manu","boskot","kita","tever","regli", "tosip","fuppy")
list2=c("blicket","sarel","fiffin","koba","modi", "chatten","jefa",
"coodle")
d$new_list <- ifelse(d$word %in% list1,"list1",
ifelse(d$word %in% list2,"list2","not_used"))
d$used=ifelse(d$new_list=="not_used",0.5,1)
#create summary values for each list
sum_d <- d %>%
group_by(new_list) %>%
summarize(
mean_seg=mean(seg_pp),
median_seg=median(seg_pp),
sd_seg=sd(seg_pp),
mean_bi=mean(bi_pp),
median_bi=median(bi_pp),
sd_bi=sd(bi_pp),
max_seg=max(seg_pp),
min_seg=min(seg_pp),
max_bi=max(bi_pp),
min_bi=min(bi_pp)
)
list_d <- data.frame(list_1=list1,list_2=list2,audio=c('<audio controls>
<source src="audio/doopy.wav" type="audio/wav"/>
</audio>'))
list_d
View(list_d)
#create audio files in a loop
audio_list_1=paste('<audio controls><source src="audio/',list1,'.wav" type="audio/wav"/></audio>',sep="")
audio_list_1
#pairs
# list1=c("toma","manu","boskot","kita","tever","regli", "tosip","fuppy")
# list2=c("blicket","sarel","fiffin","koba","modi", "chatten","jefa",
#         "coodle")
list1=c("toma","manu","boskot","kita","chatten","regli", "tosip","fuppy")
list2=c("blicket","sarel","fiffin","koba","modi", "tever","jefa",
"coodle")
d$new_list <- ifelse(d$word %in% list1,"list1",
ifelse(d$word %in% list2,"list2","not_used"))
d$used=ifelse(d$new_list=="not_used",0.5,1)
ggplot(filter(d,new_list!="not_used"),aes(seg_pp,bi_pp, label=word, color=new_list)) +
geom_point()+
geom_label()+
geom_point(data=filter(d,new_list=="not_used"), alpha=0.5)+
geom_text(data=filter(d,new_list=="not_used"), alpha=0.5)+
xlab("average segment probability")+
ylab("average biphone phonotactive probability")+
theme(legend.position=c(0.2,0.8))
ggsave("word_properties_phonotactic_probability.jpg")
sum_d <- d %>%
group_by(new_list) %>%
summarize(
mean_seg=mean(seg_pp),
median_seg=median(seg_pp),
sd_seg=sd(seg_pp),
mean_bi=mean(bi_pp),
median_bi=median(bi_pp),
sd_bi=sd(bi_pp),
max_seg=max(seg_pp),
min_seg=min(seg_pp),
max_bi=max(bi_pp),
min_bi=min(bi_pp)
)
t.test(
filter(d,new_list=="list1")$seg_pp,
filter(d,new_list=="list2")$seg_pp,
)
t.test(
filter(d,new_list=="list1")$bi_pp,
filter(d,new_list=="list2")$bi_pp,
)
source('~/Documents/Madison/InfantLearningLab/infant_effect_sizes/stimulus_selection/word_selection.R', echo=TRUE)
t.test(
filter(d,new_list=="list1")$seg_pp,
filter(d,new_list=="list2")$seg_pp,
)
sum_d
t.test(
filter(d,new_list=="list1")$seg_pp,
filter(d,new_list=="list2")$seg_pp,
var.equal = T)
t.test(
filter(d,new_list=="list1")$bi_pp,
filter(d,new_list=="list2")$bi_pp,
var.equal = T
)
#pairs
# list1=c("toma","manu","boskot","kita","tever","regli", "tosip","fuppy")
# list2=c("blicket","sarel","fiffin","koba","modi", "chatten","jefa",
#         "coodle")
list1=c("toma","manu","boskot","kita","modi","regli", "tosip","fuppy")
list2=c("blicket","sarel","fiffin","koba","tever", "chatten","jefa",
"coodle")
d$new_list <- ifelse(d$word %in% list1,"list1",
ifelse(d$word %in% list2,"list2","not_used"))
d$used=ifelse(d$new_list=="not_used",0.5,1)
ggplot(filter(d,new_list!="not_used"),aes(seg_pp,bi_pp, label=word, color=new_list)) +
geom_point()+
geom_label()+
geom_point(data=filter(d,new_list=="not_used"), alpha=0.5)+
geom_text(data=filter(d,new_list=="not_used"), alpha=0.5)+
xlab("average segment probability")+
ylab("average biphone phonotactive probability")+
theme(legend.position=c(0.2,0.8))
sum_d <- d %>%
group_by(new_list) %>%
summarize(
mean_seg=mean(seg_pp),
median_seg=median(seg_pp),
sd_seg=sd(seg_pp),
mean_bi=mean(bi_pp),
median_bi=median(bi_pp),
sd_bi=sd(bi_pp),
max_seg=max(seg_pp),
min_seg=min(seg_pp),
max_bi=max(bi_pp),
min_bi=min(bi_pp)
)
t.test(
filter(d,new_list=="list1")$seg_pp,
filter(d,new_list=="list2")$seg_pp,
var.equal = T)
t.test(
filter(d,new_list=="list1")$bi_pp,
filter(d,new_list=="list2")$bi_pp,
var.equal = T
)
?levels
setwd("~/Documents/GitHub/peekbank-hack/sample_data/smi_raw")
